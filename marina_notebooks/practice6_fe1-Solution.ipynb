{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"240\" height=\"240\" src=\"img/HS_Mu__nchen_Logo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "p.small {\n",
    "  line-height: 1;\n",
    "}\n",
    "</style>\n",
    "<body>\n",
    "    \n",
    "<p class=\"small\"> <b>Geoinformatics | Course Remote Sensing (1)</b><br> <small>Schmitt | Ulloa</small><br> <small>Summer Semester 2023</small><br></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Practice 6: Accuracy Assessment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Overview</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"main\"><b>Objectives:</b> Create your validation data and perform an accuracy assessment of the classification results from the last practice.</p>\n",
    "\n",
    "<p><b>Data:</b> For this practice, use the following files: </p>\n",
    "\n",
    "<p class=\"data\"></p>\n",
    "<ul>\n",
    "    <li> Raster files:</li>\n",
    "    <ul>\n",
    "        <li> Image classified: GeoTIFF Sentinel-2A Rasterstack (See Practice 2.)</li> \n",
    "        <li> Classification:  GeoTIFF raster with the classification result using either RF or MD (See Practice 5).</li>  \n",
    "        <li> Reference data: ATKIS and CORINE datasets.</li>\n",
    "    </ul> \n",
    "    <li> Vector file: your validation polygons in Shapefile format.</li>\n",
    "</ul>\n",
    "\n",
    "<p><b>Tasks:</b> load your S2A rasterstack and reference data in QGIS to create your validation polygons. Use your validation polygons to run an accuracy assessment on your classification rasters. Compare results and understand the different types of errors used to quantify the quality of your classification.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Procedure</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A. In QGIS: create validation data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load your Sentinel-2A Rasterstack in QGIS. On top of that, load ATKIS and CORINE datasets. To open ATKIS raster, add it as a WMS Layer. Enter username and password and connect to the server. Check that the projection is UTM 32N. Load the 'Standard' band to visualize all features. If you want, you can also load individual features, like water bodies ('Gewässer') or vegetation, for example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p6_wmsAtkis.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare all layers, using the reference data to create your polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p6_Atkis_S2a.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new set of shapefiles called \"validation.shp\" and with the help of the reference data, draw again at least 15 polygons per landclass. NOTICE: you have to use the same number, id and label of landclasses that you used for your training polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p6_valpoly.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>B. In Python: set up</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The first thing you always have to do, is to define which libraries or packages you will need. You don't need to change anything here. However, if you don't run this cell, the code won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # math and array handling\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from matplotlib.colors import ListedColormap # for plotting, import color palettes\n",
    "from osgeo import gdal, ogr, gdal_array # I/O validation data, rasters\n",
    "import rasterio as rio # Rasterio reads and writes GEOTIFF data and makes it understandable for Python\n",
    "from skimage import exposure # to perform histogram equalization of rasters\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. To do the Accuracy Assessment we are going to use some functions provided by the scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd # to write and handle dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. To display our confusion matrix we are going to use the seaborn library which we are going to install using the anaconda prompt with the \"!\" operator: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install seaborn -y\n",
    "import seaborn as sns\n",
    "\n",
    "# NOTICE: open Anaconda prompt or Command line and update conda if you get the following message: \n",
    "'''\n",
    "==> WARNING: A newer version of conda exists. <==\n",
    "  current version: 4.8.2\n",
    "  latest version: 4.8.3\n",
    "\n",
    "Please update conda by running\n",
    "\n",
    "    $ conda update -n base -c defaults conda\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Afterwards, you have to define the paths where your data is located. You can also specify where you want the results to be saved. Please adapt the following code, with the path of the files on your computer.  \n",
    "Remember to add an \"r\" at the beginning of your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where my data is located\n",
    "folder_src = r\"\"\n",
    "\n",
    "# path where I want to save my results \n",
    "folder_results = r\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C. Accuracy Assessment (EXERCISE): Understanding Confusion Matrix and Error estimation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p6_cfmatrix.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Let us make a hands-in exercise on Accuracy Assessment with the data from the lecture (Chapter \"Validation\"). The idea is to calculate yourself the different errors Total Accuracy, Completeness, and Correctness (also known as Overall Accuracy, Producer's accuracy, and User's accuracy.)  \n",
    "\n",
    "<p><a href= \"http://gis.humboldt.edu/OLM/Courses/GSP_216_Online/lesson6-2/metrics.html\">More information on Errors' estimation</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create matrix of values with landclasses as labels</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels for the classification file\n",
    "index = [\"forest\", \"water\", \"soil\", \"sum_rows\"]\n",
    "\n",
    "# create the labels for the reference data\n",
    "columns = [\"forest\", \"water\", \"soil\", \"sum_cols\"]\n",
    "\n",
    "# create some random values\n",
    "values = np.array([[758, 29, 18, 805],\n",
    "                  [72, 746, 77, 895],\n",
    "                  [384, 58, 356, 798],\n",
    "                  [1214,833,451,2498]]) # as an array\n",
    "\n",
    "# turn the array into a pandas dataframe (table)\n",
    "cm_df = pd.DataFrame(values, index=index) # read it in a table\n",
    "cm_df.columns = columns # define which ones are the labels for the columns\n",
    "print(cm_df) # show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Total or Overall accuracy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Accuracy / Overall accuracy = sum of the diagonal/total number of pixels\n",
    "\n",
    "OA = (758 + 746 + 356) / 2498\n",
    "OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Overall accuracy is', format(OA*100), '%')\n",
    "print('The Overall accuracy is {:.2f}%'.format(OA*100)) # notice, print with point, not comma\n",
    "# .2f = refers to the number of decimals to print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Completeness or Producer's accuracy or Recall</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producer's accuracy = correctly classified pixels / total number of reference sites\n",
    "\n",
    "PA_forest = 758/1214\n",
    "PA_water = 746/833\n",
    "PA_soil = 356/451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Completeness or Producer accuracy Report')\n",
    "print('The Producer accuracy for FOREST is {:.2f}%'.format(PA_forest*100)) \n",
    "print('The Producer accuracy for WATER is {:.2f}%'.format(PA_water*100)) \n",
    "print('The Producer accuracy for SOIL is {:.2f}%'.format(PA_soil*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Correctness or User's accuracy or Precision</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User's accuracy = correctly classified pixels / total number of classified sites\n",
    "\n",
    "UA_forest = 758/805\n",
    "UA_water = 746/895\n",
    "UA_soil = 356/798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correctness or User accuracy Report')\n",
    "print('The User accuracy for FOREST is {:.2f}%'.format(UA_forest*100)) \n",
    "print('The User accuracy for WATER is {:.2f}%'.format(UA_water*100)) \n",
    "print('The User accuracy for SOIL is {:.2f}%'.format(UA_soil*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Kappa coeficient</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Kappa\n",
    "\n",
    "# First, calculate K (See equation in the lecture)\n",
    "K = (1214*805 + 833*895 + 451* 798)\n",
    "# Second, list all the other variables needed\n",
    "g = 758 + 746 + 356 # correctly classified pixels\n",
    "n = 2498 # sum of all pixels\n",
    "n2 = pow(n, 2) # n to the power of 2\n",
    "# Third, use all variables to calculate kappa (See equation in the lecture)\n",
    "kappa = (g*n-K)/(n2 - K)\n",
    "\n",
    "print('The Kappa coeficient is {:.2f}'.format(kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. We can play around with another data. In the next example, take a look at the following data. \n",
    " - y_true: are the real values of the pixels\n",
    " - y_pred: are the values predicted by the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [2, 0, 2, 2, 0, 1, 0, 2, 1, 2, 2, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. How are the classification classes named and how many are they? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 classes: 0, 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. To which dataset \"reference\" and \"classification\", correspond \"y_true\" and \"y_pred\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_true = reference, y_pred = classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Using y_true, y_pred, build a confusion matrix, using the function 'confusion_matrix()'. Store the result in an object called 'confu_test'. For more info, visit: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confu_test = confusion_matrix(y_true, y_pred)\n",
    "confu_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Plot your object 'confu_test' using the following code:  \n",
    "> plt.figure(figsize=(10,7))  \n",
    "sns.heatmap(confu_test, annot=True, fmt='g',cmap = 'YlGnBu')  \n",
    "plt.xlabel('classes - predicted')  \n",
    "plt.ylabel('classes - truth')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confu_test, annot=True, fmt='g',cmap = 'YlGnBu')\n",
    "plt.xlabel('classes - predicted')\n",
    "plt.ylabel('classes - truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Manipulate the arrays 'y_true' and 'y_pred' to increase the accuracy of class '1'. (hint: there are 2 possible things to do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First option: increase the number of values for class 1. This also would mean that probably you will have to increase the number of values for class '2' to make it balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [2, 0, 2, 2, 0, 1, 0, 2, 1, 2, 2, 1, 1, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second option: keep the same number of values for the class '1' but match the number true with predicted data for this class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 2, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Now we can run exactly the same analysis from exercise Nr.8, using a function in Python that summarizes all the previous calculations in one step. For this, we will use the same dataset, but change the labels of the landclasses to values:   \n",
    "  FROM [\"forest\", \"water\", \"soil\"] TO [1, 2, 3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels of rows and columns\n",
    "index = [1, 2, 3, 'r_sum']\n",
    "columns = [1, 2, 3, 'c_sum']\n",
    "# fill in values\n",
    "values = np.array([[758, 29, 18, 805],\n",
    "                  [72, 746, 77, 895],\n",
    "                  [384, 58, 356, 798],\n",
    "                  [1214,833,451,2498]])\n",
    "\n",
    "# turn the array into a pandas dataframe (table)\n",
    "cm_df = pd.DataFrame(values, index=index)\n",
    "cm_df.columns = columns\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Accuracy Assessment function on Python</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure the floating point precision of our output\n",
    "np.set_printoptions(precision=2) # 2 decimals\n",
    "\n",
    "# function for error estimations (AA)\n",
    "def accAss(name, gcm, n_classes):\n",
    "    #Completeness\n",
    "    print('Accuracy Assessment for',name,'Prediction')\n",
    "    comp = np.zeros(n_classes)\n",
    "    for i in range(n_classes):\n",
    "        comp[i]=gcm[i+1][i+1]/gcm[i+1]['r_sum']\n",
    "    print('Producer Accuracy / Recall [%]:', (comp*100))\n",
    "    \n",
    "    #Correctness\n",
    "    corr = np.zeros(n_classes)\n",
    "    for i in range(n_classes):\n",
    "        corr[i]=gcm[i+1][i+1]/gcm['c_sum'][i+1]\n",
    "    print('User Accuracy / Precision [%]:',(corr*100))                         \n",
    "    \n",
    "    #Total Accuracy\n",
    "    diag = np.zeros(n_classes)\n",
    "    for i in range(n_classes):\n",
    "        diag[i]=gcm[i+1][i+1]\n",
    "    g = np.sum(diag)\n",
    "    n = gcm['c_sum']['r_sum']\n",
    "    ta = g/n\n",
    "    print('Total Accuracy [%%]: %.2f' % (ta*100))\n",
    "    \n",
    "    #Correlation\n",
    "    corr_v = np.zeros(n_classes)\n",
    "    for i in range(n_classes):\n",
    "        corr_v[i]=gcm[i+1]['r_sum']*gcm['c_sum'][i+1]\n",
    "    K = np.sum(corr_v)\n",
    "    \n",
    "    #Cohen's Kappa\n",
    "    k=(g*n-K)/((n*n)-K)\n",
    "    print(\"Cohens's Kappa: %.2f\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Apply this function on the same example of the lecture (exercise Nr.15), and compare with the results you calculated by hand (exercise Nr.8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function for AA on table 'cm_df', with 3 classes\n",
    "accAss('Lecture Example',cm_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>D. Load raster and vector data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. On this section you will load your raster and vector data and perform an accuracy assessment of your classification. The process of loading the data is exactly the same as for last week: classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Sentinel2-A raster</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Load the raster file that you want to. Adapt the code to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the classified image (Setinel-2A Rasterstack) \n",
    "s2_stack = os.path.join(folder_src, 'raster','S2_20220304_Cliped_Reflectance_RGBNIR.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Extract the information of your raster data. Here, you make the attributes readable for the classification algorithm. Afterwards, the data is being transformed into a Numpy array for easier calculations.\n",
    "Check the printing commands and the variables that are being used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data\n",
    "#In this script we are Using gdal.open() instead of rio.open()\n",
    "img_ds = gdal.Open(s2_stack, gdal.GA_ReadOnly)\n",
    "\n",
    "img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n",
    "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "for b in range(img.shape[2]):\n",
    "    img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "\n",
    "print(\"Raster format is:\", gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    \n",
    "# store the variables above in a more meaningful way. You will use these variables later.\n",
    "row = img_ds.RasterYSize\n",
    "col = img_ds.RasterXSize\n",
    "band_number = img_ds.RasterCount\n",
    "# Values bigger when 1 will be set to 1\n",
    "img[img>1] = 1\n",
    "\n",
    "print(\"Raster number of rows: {}\".format(row))\n",
    "print(\"Raster number of columns: {}\".format(col))\n",
    "print(\"Raster number of bands: {}\".format(band_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Minimum Distance and Random Forest classification rasters</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Define individual paths for your classification rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the classification rasters, depending of the algorithm used\n",
    "#Random Forest\n",
    "rf_pred_path = os.path.join(folder_src, 'rf_nt250.tif')\n",
    "#Minimum Distance\n",
    "knn_pred_path = os.path.join(folder_src, 'md_classi.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Now we are going to load the prediction result rasters from the last practice and see if the dimensions are correct (they should match the extent of your Sentinel-2a image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions of RF classification\n",
    "\n",
    "# open file\n",
    "rf_open = gdal.Open(rf_pred_path, gdal.GA_ReadOnly)\n",
    "# extract metadata\n",
    "rf_meta = np.zeros((rf_open.RasterYSize, rf_open.RasterXSize, rf_open.RasterCount), gdal_array.GDALTypeCodeToNumericTypeCode(rf_open.GetRasterBand(1).DataType))\n",
    "for b in range(rf_meta.shape[2]):\n",
    "    rf_meta[:, :, b] = rf_open.GetRasterBand(b + 1).ReadAsArray()\n",
    "# define the new shape for the rf classification\n",
    "new_shape = (rf_meta.shape[0], rf_meta.shape[1])\n",
    "# reshape\n",
    "rf_pred = rf_meta[:, :, :int(rf_meta.shape[2])].reshape(new_shape)\n",
    "\n",
    "# compare the dimensions. They are the same as S2a\n",
    "print(\"Dimensions of RF after 'reshape()' are\",rf_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions of MD classification = prediction\n",
    "\n",
    "# open file\n",
    "knn_open = gdal.Open(knn_pred_path, gdal.GA_ReadOnly)\n",
    "# extract metadata\n",
    "knn_meta = np.zeros((knn_open.RasterYSize, knn_open.RasterXSize, knn_open.RasterCount), gdal_array.GDALTypeCodeToNumericTypeCode(knn_open.GetRasterBand(1).DataType))\n",
    "for b in range(knn_meta.shape[2]):\n",
    "    knn_meta[:, :, b] = knn_open.GetRasterBand(b + 1).ReadAsArray()\n",
    "# define the new shape for the md classification\n",
    "new_shapeknn = (knn_meta.shape[0], knn_meta.shape[1])\n",
    "# reshape\n",
    "knn_pred = knn_meta[:, :, :int(knn_meta.shape[2])].reshape(new_shapeknn)\n",
    "\n",
    "# compare the dimensions. They are the same as S2a\n",
    "print(\"Dimensions of MD after 'reshape()' are\",knn_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load validation shapefile</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Load your validation data (shapefiles). Define the column that has the attributes (i.e. 'landclass' OR 'class' OR 'landcover').\n",
    "Adapt the code to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation as shape files\n",
    "validation = os.path.join(folder_src,'vector','test_20220304.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the attributes name of your classes in the shape file (field name of the classes)?\n",
    "attribute = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Recheck if the validation data is in the correct format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation data and show all shape attributes\n",
    "shape_dataset = ogr.Open(validation)\n",
    "shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "# extract the names of all attributes (fieldnames) in the shape file\n",
    "attributes = []\n",
    "ldefn = shape_layer.GetLayerDefn()\n",
    "for n in range(ldefn.GetFieldCount()):\n",
    "    fdefn = ldefn.GetFieldDefn(n)\n",
    "    attributes.append(fdefn.name)\n",
    "    \n",
    "# print the attributes\n",
    "print('Available attributes in the shape file are: {}'.format(attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. Rasterize your validation polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from shape file and rasterize\n",
    "\n",
    "shape_dataset = ogr.Open(validation)\n",
    "shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "mem_drv = gdal.GetDriverByName('MEM')\n",
    "mem_raster = mem_drv.Create('',img_ds.RasterXSize,img_ds.RasterYSize,1,gdal.GDT_UInt16)\n",
    "mem_raster.SetProjection(img_ds.GetProjection())\n",
    "mem_raster.SetGeoTransform(img_ds.GetGeoTransform())\n",
    "mem_band = mem_raster.GetRasterBand(1)\n",
    "mem_band.Fill(0)\n",
    "mem_band.SetNoDataValue(0)\n",
    "\n",
    "att_ = 'ATTRIBUTE='+attribute\n",
    "# http://gdal.org/gdal__alg_8h.html#adfe5e5d287d6c184aab03acbfa567cb1\n",
    "# http://gis.stackexchange.com/questions/31568/gdal-rasterizelayer-doesnt-burn-all-polygons-to-raster\n",
    "err = gdal.RasterizeLayer(mem_raster, [1], shape_layer, None, None, [1],  [att_,\"ALL_TOUCHED=TRUE\"])\n",
    "assert err == gdal.CE_None\n",
    "\n",
    "val = mem_raster.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Voilà! Now you have your validation polygons in the same resolution and projection as your Sentinel-2 Rasterstack. The next task is to extract the validation pixels (OR 'samples') from the Rasterstack.\n",
    "The samples will be used for measuring the accuracy of the classification raster. In total, I am extracting 1091 samples from the matrix 'X'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of validation pixels:\n",
    "n_samples = (val > 0).sum()\n",
    "print('{n} validation samples'.format(n=n_samples))\n",
    "\n",
    "# What are our classification labels?\n",
    "labels = np.unique(val[val > 0])\n",
    "print('validation data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
    "\n",
    "# Subset the image dataset with the image = X\n",
    "# Mask the classes on the validation dataset = y\n",
    "# These will have n_samples rows\n",
    "X_rf = rf_pred[val > 0]\n",
    "y = val[val > 0]\n",
    "\n",
    "print('Our X matrix is sized: {sz}'.format(sz=X_rf.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. Why the dimensions of both X and y are the same? How many bands each object has? Compare this result with the step Nr.10 from Practice 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions of X and y are the same, because X is being selected based on positived values for y (i.e. X_rf = rf_pred[val > 0]).   \n",
    "Each object has only 1 band.  \n",
    "In Practice Nr.5 we tried to select in this step the number of training samples. Here we are selecting the number of validation samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. What determines the number of samples from the polygons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size and number of the validation polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Visualization of data</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. Plot all your files: S2A rasterstack, validation polygons, classification rasters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color palette\n",
    "#\"Water\", \"Ground\", \"Coniferous\", \"Deciduous\", \"Roof\", \"AgricultureAreaType1\", \"AgricultureAreaType2\"\n",
    "custom_cmap = ListedColormap([\"lightseagreen\",\"gray\",\"darkgreen\",\"lightgreen\",\"red\",\"yellow\",\"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the graphs\n",
    "#plot=plt.subplots(figsize=(20,20))\n",
    "fig,ax = plt.subplots(figsize=(20,20))\n",
    "# Define the spacing among graphs\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "# Plot the rasterstack with an Adaptive Equalization\n",
    "plt.subplot(221)\n",
    "img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "plot_rs = plt.imshow(img_adapteq)\n",
    "plt.title('Sentinel-2 RasterStack\\n RGB, colors adjusted', fontsize=20)\n",
    "## More info: https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html\n",
    "\n",
    "# Plot the blue band with the training polygons\n",
    "plt.subplot(222)\n",
    "plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "# Add your training polygons on top. NOTICE that you have here validation and not training polygons\n",
    "plot_tr = plt.imshow(val, cmap='jet', alpha=0.5)\n",
    "plt.title(\"Sentinel-2 blue band\\n  with training polygons\", fontsize=20)\n",
    "                  \n",
    "# Plot the RandomForest classification\n",
    "plt.subplot(223)\n",
    "plot_rf = plt.imshow(rf_pred, cmap=custom_cmap)\n",
    "plt.title('Random Forest Classification\\n n-trees = 250', fontsize=20)\n",
    "## I eliminated here the colorbar, for visualization purposes\n",
    "\n",
    "# Plot the Minimum Distance classification\n",
    "plt.subplot(224)\n",
    "plot_md = plt.imshow(knn_pred, cmap=custom_cmap)\n",
    "plt.title('Minimum Distance Classification', fontsize=20)\n",
    "## I eliminated here the colorbar, for visualization purposes\n",
    "\n",
    "# show your plots. This command has to be run only once.\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>E. Accuracy Assessment: Estimate Confusion Matrix and Errors on your classification</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. Plot the confusion matrix of your Random Forest classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function 'confusion_matrix' from scikit-learn to plot the confusion matrix of your RF classification\n",
    "cm_val = confusion_matrix(y, X_rf).T # invert rows and cols\n",
    "\n",
    "# X_rf = prediction from rf\n",
    "# X_md = prediction from md\n",
    "# y = 'true pixel values' = reference dataset = validation shapefile\n",
    "\n",
    "# define size of plot\n",
    "plt.figure(figsize=(10,7))\n",
    "# color the table. The higher the value, the darker the color\n",
    "sns.heatmap(cm_val, annot=True, fmt='g',cmap = 'YlGnBu' )\n",
    "# labels\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Classification')\n",
    "# plot\n",
    "plt.show()\n",
    "# print text\n",
    "print('Confusion matrix of Random Forest classification\\n Landclasses:\\n 0 = Water\\n 1 = Ground\\n 2 = Coniferous\\n 3 = Deciduous\\n 4 = Roof\\n 5 = AgricultureAreaType1\\n 6 = AgricultureAreaType2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. Drop your results in a pandas table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a simple cross tabulation of two (or more) factors. By default computes a frequency table of the factors unless an array of values and an aggregation function are passed.\n",
    "rcm = pd.crosstab(y, X_rf, margins=True).T # invert rows and cols\n",
    "\n",
    "\n",
    "# rename the colums and rows of the table\n",
    "rcm.rename(columns={'All':'c_sum'}, index={'All':'r_sum'}, inplace=True)\n",
    "print(rcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. Apply the Acuracy Assessment function on the confusion matrix of your Random Forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function for AA on table 'rcm', with 7 classes\n",
    "accAss('Random Forest',rcm, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. Verify 'by hand' that the errors estimation of the RF classification is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OA = (315 + 339 + 199 + 63 + 232 + 506 + 593) / 2416\n",
    "print('The Overall accuracy is {:.2f}%'.format(OA*100))\n",
    "\n",
    "PA_Water = 315/315\n",
    "PA_Ground = 339/342\n",
    "PA_Coniferous = 199/207\n",
    "PA_Deciduous = 63/92\n",
    "PA_Roof = 232/351\n",
    "PA_AgricultureAreaType1 = 506/510\n",
    "PA_AgricultureAreaType2 = 593/599\n",
    "\n",
    "UA_Water = 315/315\n",
    "UA_Ground = 339/419\n",
    "UA_Coniferous = 199/204\n",
    "UA_Deciduous = 63/93\n",
    "UA_Roof = 232/244\n",
    "UA_AgricultureAreaType1 = 506/527\n",
    "UA_AgricultureAreaType2 = 593/614\n",
    "\n",
    "# Calculate Kappa\n",
    "\n",
    "# First, calculate K (equation 6 in the lecture)\n",
    "K = (315*315 + 342*419 + 207*204 + 92*93 + 351*244 + 510*527 + 599*614)\n",
    "# Second, list all the other variables needed\n",
    "g = 315 + 339 + 199 + 63 + 232 + 506 + 593 # correctly classified pixels\n",
    "n = 2416 # sum of all pixels\n",
    "n2 = pow(n, 2) # n to the power of 2\n",
    "# Third, use all variables to calculate kappa (equation 7 in the lecture)\n",
    "kappa = (g*n-K)/(n2 - K)\n",
    "\n",
    "print('The Kappa coeficient is {:.2f}'.format(kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. Calculate the confusion matrix and estimate the errors of your Minimum Distance classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the image dataset with the image = X\n",
    "# Mask the classes on the validation dataset = y\n",
    "# These will have n_samples rows\n",
    "X_md = knn_pred[val > 0]\n",
    "y = val[val > 0]\n",
    "\n",
    "# use the function 'confusion_matrix' from scikit-learn to plot the confusion matrix of your RF classification\n",
    "cm_val_md = confusion_matrix(y, X_md).T # invert rows and cols\n",
    "print(cm_val_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a simple cross tabulation of two (or more) factors. By default computes a frequency table of the factors unless an array of values and an aggregation function are passed.\n",
    "md_cm = pd.crosstab(y, X_md, margins=True).T  # invert rows and cols\n",
    "\n",
    "# rename the colums and rows of the table\n",
    "md_cm.rename(columns={'All':'c_sum'}, index={'All':'r_sum'}, inplace=True)\n",
    "print(md_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function for AA on table 'rcm', with 7 classes\n",
    "accAss('Minimum Distance',md_cm, 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. Plot the confusion matrix of your MD classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define size of plot\n",
    "plt.figure(figsize=(10,7))\n",
    "# color the table. The higher the value, the darker the color\n",
    "sns.heatmap(cm_val_md, annot=True, fmt='g',cmap = 'YlGnBu' )\n",
    "# labels\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Classification')\n",
    "# plot\n",
    "plt.show()\n",
    "# print text\n",
    "print('Confusion matrix of Minimum Distance classification\\n Landclasses:\\n 0 = Water\\n 1 = Ground\\n 2 = Coniferous\\n 3 = Deciduous\\n 4 = Roof\\n 5 = AgricultureAreaType1\\n 6 = AgricultureAreaType2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. Is there any difference in the AA of every classification? What are the reasons for this? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(discussed in the practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <small>This tutorial was prepared with the support from Gabriel Cevallos. June 2020</small> </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
