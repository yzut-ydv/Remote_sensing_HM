{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"240\" height=\"240\" src=\"img/HS_Mu__nchen_Logo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "p.small {\n",
    "  line-height: 1;\n",
    "}\n",
    "</style>\n",
    "<body>\n",
    "    \n",
    "<p class=\"small\"> <b>Geoinformatics | Course Remote Sensing (1)</b><br> <small>Schmitt | Ulloa</small><br> <small>Summer Semester 2021</small><br></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Practice 5: Supervised classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Overview</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"main\"><b>Objectives:</b> Perform a supervised classification of your AOI, on a multiband Sentinel image or Rasterstack. Test different algorithms for this.</p>\n",
    "\n",
    "<p><b>Data:</b> For this practice, use the following files: </p>\n",
    "\n",
    "<p class=\"data\"></p>\n",
    "<ul>\n",
    "    <li> Raster file: GeoTIFF Sentinel-2A Rasterstack (see Practice 2)</li> \n",
    "    <li> Vector file: your training polygons in Shapefile format (See Practice 3).</li>\n",
    "</ul>\n",
    "\n",
    "<p><b>Tasks:</b> load your rasterfile and your training data in Python and perform a supervised classification. Test different algorithms and different values for the parameters. Export the classification files and visualize them.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Procedure</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A. Prepare the settings on your computer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_wf1.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first thing you always have to do, is to define which libraries or packages you will need. You don't need to change anything here. However, if you don't run this cell, the code won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os \n",
    "from osgeo import gdal, ogr, gdal_array # I/O image data\n",
    "import numpy as np # math and array handling\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from matplotlib.colors import ListedColormap # to import certain defined color palettes for plotting your results\n",
    "from sklearn.ensemble import RandomForestClassifier # classifier\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix  # calculating measures for accuracy assessment\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage import exposure # for adjustment of rasterstack (histogram equalization, etc)\n",
    "\n",
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Afterwards, you have to define the paths where your data is located. You can also specify where you want the results to be saved. Please adapt the following code, with the path of the files on your computer.   \n",
    "Remember to add an \"r\" at the beginning of your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where my data is located\n",
    "folder_src = r\"C:\\Users\\ulloa-to\\PythonProjects\\practices_fe1_ss2020\\scripts\\data\\p5\"\n",
    "\n",
    "\n",
    "# path where I want to save my results \n",
    "folder_results = r\"C:\\Users\\ulloa-to\\PythonProjects\\practices_fe1_ss2020\\scripts\\data\\p5\\results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Here I added some general setting commands. Run this command for better performance on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many cores should be used?\n",
    "n_cores = -1\n",
    "# -1 -> all available cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>B. Load your data in Python</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_wf2.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the raster file that you want to classify. Adapt the code to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command pastes the path to your file (defined by 'folder_src') and the name of your file\n",
    "# since my raster is located in a subfolder 'raster', I include it as well \n",
    "s2_stack = os.path.join(folder_src,'raster/S2A_L2A_T32UPU_rasterstack.tif')\n",
    "s2_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Extract the information of your raster data. Here, you make the attributes readable for the classification algorithm. Afterwards, the data is being transformed into a Numpy array for easier calculations.  \n",
    "Check the printing commands and the variables that are being used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data\n",
    "#In this script we are Using gdal.open() instead of rio.open()\n",
    "img_ds = gdal.Open(s2_stack, gdal.GA_ReadOnly)\n",
    "\n",
    "img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n",
    "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "for b in range(img.shape[2]):\n",
    "    img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "\n",
    "print(\"Raster format is:\", gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    \n",
    "# store the variables above in a more meaningful way. You will use these variables later.\n",
    "row = img_ds.RasterYSize\n",
    "col = img_ds.RasterXSize\n",
    "band_number = img_ds.RasterCount\n",
    "\n",
    "print(\"Raster number of rows: {}\".format(row))\n",
    "print(\"Raster number of columns: {}\".format(col))\n",
    "print(\"Raster number of bands: {}\".format(band_number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Reshape your raster to turn it into a Numpy Array for the classification. We do not need the location anymore, since we will be working with the distance among pixels in terms of the difference of reflectance among them.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "img_as_array = img[:, :, :np.int(img.shape[2])].reshape(new_shape)\n",
    "\n",
    "print('Reshaped from {o} to {n}'.format(o=img.shape, n=img_as_array.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Load your training data (shapefiles). Define the column that has the attributes (i.e. 'landclass' OR 'class' OR 'landcover').   \n",
    "Adapt the code to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command pastes the path to your file (defined by 'folder_src') and the name of your file\n",
    "# since my raster is located in a subfolder 'vector', I include it as well\n",
    "training = os.path.join(folder_src,'vector/train.shp')\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the numerical attribute of your classes in the shapefile?\n",
    "attribute = 'id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Extract the information of your training data. Here, you make the attributes readable for the classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data and show all shapefile attributes\n",
    "shape_dataset = ogr.Open(training)\n",
    "shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "# extract the names of all attributes (fieldnames) in the shape file\n",
    "attributes = [] # empty list where the attributes will be saved\n",
    "ldefn = shape_layer.GetLayerDefn() # encapsulates the attribute schema of the features of the layer\n",
    "for n in range(ldefn.GetFieldCount()):\n",
    "    fdefn = ldefn.GetFieldDefn(n)\n",
    "    attributes.append(fdefn.name)\n",
    "    \n",
    "# print the attributes\n",
    "print('Available attributes in the shapefile are: {}'.format(attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Rasterize your training polygons. This means, that your polygons won't be a shapefile anymore, but they will be turned into little rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the structure of your Sentinel2 image to pass this information to the new rasterized polygons\n",
    "mem_drv = gdal.GetDriverByName('MEM')\n",
    "mem_raster = mem_drv.Create('',img_ds.RasterXSize,img_ds.RasterYSize,1,gdal.GDT_UInt16)\n",
    "mem_raster.SetProjection(img_ds.GetProjection())\n",
    "mem_raster.SetGeoTransform(img_ds.GetGeoTransform())\n",
    "mem_band = mem_raster.GetRasterBand(1)\n",
    "mem_band.Fill(0)\n",
    "mem_band.SetNoDataValue(0)\n",
    "\n",
    "att_ = 'ATTRIBUTE='+attribute\n",
    "\n",
    "# rasterize your polygons\n",
    "err = gdal.RasterizeLayer(mem_raster, [1], shape_layer, None, None, [1],  [att_,\"ALL_TOUCHED=TRUE\"])\n",
    "assert err == gdal.CE_None\n",
    "\n",
    "roi = mem_raster.ReadAsArray()\n",
    "\n",
    "# for more info: \n",
    "# http://gdal.org/gdal__alg_8h.html#adfe5e5d287d6c184aab03acbfa567cb1\n",
    "# http://gis.stackexchange.com/questions/31568/gdal-rasterizelayer-doesnt-burn-all-polygons-to-raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Voilà! Now you have your polygons in the same resolution and projection as your Sentinel-2 Rasterstack. The next task is to extract the training pixels (OR 'samples') from the Rasterstack.  \n",
    "The samples will be used for training the classification algorithm. In total, I am extracting 435 samples from the matrix 'X', using the array 'y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training pixels:\n",
    "n_samples = (roi > 0).sum()\n",
    "print('{n} training samples'.format(n=n_samples))\n",
    "\n",
    "# What are our classification labels?\n",
    "labels = np.unique(roi[roi > 0])\n",
    "print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
    "\n",
    "# Subset the image dataset with the training image = X\n",
    "# Mask the classes on the training dataset = y\n",
    "# These will have n_samples rows\n",
    "X = img[roi > 0, :]\n",
    "y = roi[roi > 0]\n",
    "\n",
    "print('Our X matrix is sized: {sz}'.format(sz=X.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. You can plot this data, to have an overview of what you have done so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your raster\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "plt.title('RS image - first band')\n",
    "\n",
    "# Plot your training polygons\n",
    "plt.subplot(122)\n",
    "plt.imshow(roi, cmap=plt.cm.Spectral)\n",
    "plt.title('Training Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. In the last function, do you know what the numbers 121 or 122 mean?  \n",
    "These numbers refer to : nrows, ncols, and index, in order.   \n",
    "Try the previous code again and this time place one plot below the other.   \n",
    "For more parameters, check: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.subplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Do you want to plot the training polygons on top of your raster? Use the same functions as before but get rid of the \"plt.subplot()\" command.  \n",
    "For the shapefile use: \"plt.imshow(roi, cmap='jet', alpha=0.5)\".  \n",
    "Keep also in mind that in this case it is enough with only one \"plt.title('text')\" command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your raster\n",
    "plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "plt.title('RS image - first band')\n",
    "plt.imshow(roi, cmap='jet', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this practice, you will load your raster + training polygons and apply different algorithms. We will start with Minimum Distance.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>B. Classification - MD</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_wf3.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Minimum distance</h4>\n",
    "\n",
    "<h5>The minimum distance classifier is used to classify unknown image data to classes which minimize the distance between the image data and the class in multi-feature space. The distance is defined as an index of similarity so that the minimum distance is identical to the maximum similarity.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_md.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href= \"https://www.researchgate.net/publication/294596525_An_investigation_of_the_design_and_use_of_feed-forward_artificial_neural_networks_in_the_classification_of_remotely_sensed_images\">Source image</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Perform a Minimum Distance classification. For this, you will use the function K-NearestNeighbors with K=1, from the scikit-learn package. In this function, you are using Euclidean Distance, which is the distance used in 'Minimum Distance'.    \n",
    "In this step, you are training the algorith using your training data.  \n",
    "More info: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1, n_jobs=n_cores)\n",
    "X = np.nan_to_num(X)\n",
    "knnraster = knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. With the algorithm trained, now you can predict the rest of the pixels of your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the rest of the image\n",
    "# Use the raster in the format assigned on question nr.6\n",
    "img_as_array = np.nan_to_num(img_as_array)\n",
    "# THIS IS YOUR CLASSIFICATION OUTPUT\n",
    "knn_prediction = knn.predict(img_as_array)\n",
    "print('Shape knn prediction {}'.format(knn_prediction.shape))\n",
    "knn_prediction = knn_prediction.reshape(img[:, :, 0].shape)\n",
    "print('Reshaped back to {}'.format(knn_prediction.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Plot your results. In my training dataset, I have the following classes:  \n",
    " - water = 1  \n",
    " - urban residential = 2  \n",
    " - urban industrial = 3  \n",
    " - agricultural = 4  \n",
    " - broadleaved forest = 5  (Laubwald)  \n",
    " - coniferous forest = 6  (Nadelwald)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assing colors to each class. The order of the colors depends on the order of the landclasses\n",
    "custom_cmap = ListedColormap([\"blue\",\"red\",\"darkgrey\",\"burlywood\", \"darkgreen\",\"green\"])\n",
    "# for example, here water = \"lightseagreen\"\n",
    "\n",
    "# plot your classification\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "ax.set_title('Classification Minimum Distance\\n Sentinel-2 Rasterstack', fontsize = 20) # use '\\n' to start a new line\n",
    "plot_md =ax.imshow(knn_prediction, cmap=custom_cmap) # indicate which file will be plotted, add colors\n",
    "# set parameters for colorbar\n",
    "cbar_md = plt.colorbar(plot_md,shrink=0.6) \n",
    "cbar_md.set_ticks([1,2,3,4,5,6])\n",
    "cbar_md.set_ticklabels([\"water\", \"urban residential\", \"urban industrial\", \"agriculture\", \"deciduous forest\", \"coniferous forest\"])\n",
    "cbar_md.ax.tick_params(labelsize=20) # adapt font size of ticks\n",
    "# show your plot\n",
    "plt.show()\n",
    "\n",
    "# More info on plotting functions: \n",
    "# https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n",
    "# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.colorbar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. How good is your classification? What can you do to improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_wf4.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Export your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where the image will be saved\n",
    "classification_image=os.path.join(folder_results,'md_classi.tif')\n",
    "\n",
    "# define structure of your output file\n",
    "driver = gdal.GetDriverByName(\"gtiff\")\n",
    "cols = img.shape[1]\n",
    "rows = img.shape[0]\n",
    "outdata = driver.Create(classification_image, cols, rows, 1, gdal.GDT_UInt16)\n",
    "outdata.SetGeoTransform(img_ds.GetGeoTransform())##sets same geotransform as input\n",
    "outdata.SetProjection(img_ds.GetProjection())##sets same projection as input\n",
    "\n",
    "# specify which image you want to save\n",
    "outdata.GetRasterBand(1).WriteArray(knn_prediction)\n",
    "\n",
    "#saves to disk!!\n",
    "outdata.FlushCache() \n",
    "\n",
    "print('Image saved to: {}'.format(classification_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C. Classification - RF</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_wf3.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random Forest</h4>\n",
    "<h5>A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_rf.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href= \"https://www.javatpoint.com/machine-learning-random-forest-algorithm\">Source image</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Perform a Random Forest classification. (Basically, train the algorith using your training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of samples we are using\n",
    "X.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a number of trees that should be used (default = 100)\n",
    "est = 250\n",
    "\n",
    "# run the RF algorithm\n",
    "rf = RandomForestClassifier(n_estimators=est, verbose=1, n_jobs=n_cores)\n",
    "X = np.nan_to_num(X)\n",
    "rf2 = rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. With the algorithm trained, now you can predict the rest of the pixels of your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prediction = rf.predict(img_as_array)\n",
    "print('Shape prediction {}'.format(class_prediction.shape))\n",
    "class_prediction = class_prediction.reshape(img[:, :, 0].shape)\n",
    "print('Reshaped back to {}'.format(class_prediction.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Plot your results. In my training dataset, I have the following classes:  \n",
    " - water = 1  \n",
    " - urban residential = 2  \n",
    " - urban industrial = 3  \n",
    " - agricultural = 4  \n",
    " - broadleaved forest = 5  (Laubwald)  \n",
    " - coniferous forest = 6  (Nadelwald)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assing colors to each class. The order of the colors depends on the order of the landclasses\n",
    "custom_cmap = ListedColormap([\"lightseagreen\",\"red\",\"darkgrey\",\"burlywood\", \"darkgreen\",\"green\"])\n",
    "# for example, here water = \"lightseagreen\"\n",
    "\n",
    "# plot your classification\n",
    "fig,ax = plt.subplots(figsize=(20,20))\n",
    "ax.set_title('Random Forest Classification\\n n-trees = 250', fontsize = 35) # use '\\n' to start a new line\n",
    "# indicate which file will be plotted, add colors\n",
    "plot_rf =ax.imshow(class_prediction, cmap=custom_cmap) \n",
    "# set parameters for colorbar\n",
    "cbar_rf = plt.colorbar(plot_rf,shrink=0.6) \n",
    "cbar_rf.set_ticks([1,2,3,4,5,6])\n",
    "cbar_rf.set_ticklabels([\"water\", \"urban residential\", \"urban industrial\", \"agriculture\", \"deciduous forest\", \"coniferous forest\"])\n",
    "cbar_rf.ax.tick_params(labelsize=25) # adapt font size of ticks\n",
    "# show your plot\n",
    "plt.show()\n",
    "\n",
    "# More info on plotting functions: \n",
    "# https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n",
    "# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.colorbar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. How good is your classification? What can you do to improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Run RF again, and compare the results with different values of:   \n",
    "    * n_estimators (number of trees): 100, 500, 1000\n",
    "    * bootstrap = False\n",
    "    * max_samples = 50, 100, 500\n",
    "\n",
    "What is the importance of these parameters?  \n",
    "Check the parameters of this function here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"img/img_p5_wf4.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. Export your results (use the same block of functions as for KNN, adapt values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where the image will be saved\n",
    "classification_image=os.path.join(folder_results,'rf_nt250.tif')\n",
    "cols = img.shape[1]\n",
    "rows = img.shape[0]\n",
    "\n",
    "# define structure of your output file\n",
    "driver = gdal.GetDriverByName(\"gtiff\")\n",
    "outdata = driver.Create(classification_image, cols, rows, 1, gdal.GDT_UInt16)\n",
    "outdata.SetGeoTransform(img_ds.GetGeoTransform())##sets same geotransform as input\n",
    "outdata.SetProjection(img_ds.GetProjection())##sets same projection as input\n",
    "\n",
    "# specify which image you want to save\n",
    "outdata.GetRasterBand(1).WriteArray(class_prediction)\n",
    "\n",
    "#saves to disk!!\n",
    "outdata.FlushCache() \n",
    "\n",
    "print('Image saved to: {}'.format(classification_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>D. Summary</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Visualize all your interim and final results (Zwischen- und Endergebnisse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the graphs\n",
    "plot=plt.subplots(figsize=(20,20))\n",
    "# Define the spacing among graphs\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "# Plot the rasterstack with an Adaptive Equalization\n",
    "plt.subplot(221)\n",
    "img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "plot_rs = plt.imshow(img_adapteq)\n",
    "plt.title('Sentinel-2 RasterStack\\n RGB, colors adjusted', fontsize=20)\n",
    "## More info: https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html\n",
    "\n",
    "# Plot the blue band with the training polygons\n",
    "plt.subplot(222)\n",
    "plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "# Add your training polygons on top\n",
    "plot_tr = plt.imshow(roi, cmap='jet', alpha=0.5)\n",
    "plt.title(\"Sentinel-2 blue band\\n  with training polygons\", fontsize=20)\n",
    "                  \n",
    "# Plot the RandomForest classification\n",
    "plt.subplot(223)\n",
    "plot_rf = plt.imshow(class_prediction, cmap=custom_cmap)\n",
    "plt.title('Random Forest Classification\\n n-trees = 250', fontsize=20)\n",
    "## I eliminated here the colorbar, for visualization purposes\n",
    "\n",
    "# Plot the Minimum Distance classification\n",
    "plt.subplot(224)\n",
    "plot_md = plt.imshow(knn_prediction, cmap=custom_cmap)\n",
    "plt.title('Minimum Distance Classification', fontsize=20)\n",
    "## I eliminated here the colorbar, for visualization purposes\n",
    "\n",
    "# show your plots. This command has to be run only once.\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. Can you summarize your results in the following terms?:  \n",
    "   - Which algorithm provided better results? Why?   \n",
    "   - What is it necessary to improve classification results? (think about the parameters you have used: number of landclasses, number of samples, number training polygons, quality of the training polygons made, number of trees [RF], type of classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <small>This tutorial was prepared with the support from Gabriel Cevallos. May 2020</small> </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
